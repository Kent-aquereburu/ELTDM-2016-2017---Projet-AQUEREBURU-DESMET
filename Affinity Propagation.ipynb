{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation en pySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est-ce que c'est ?\n",
    "L'_Affinity Propagation_ est un algorithme de clustering (apprentissage non supervisé) ne requérant pas pour l'utilisateur de choisir le nombre initial de partitions souhaitées. Cela est particulièrement utile lorsque qu'il n'existe pas d'_a priori_ concernant le nombre de clusters.\n",
    "En cela, l'_Affinity propagation_ s'oppose aux méthodes classiques (K-means, mean-shift, etc.).\n",
    "\n",
    "<ol> \n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Test_de_l'affinity_propagation_de_Scikit_Learn](#Test-de-l'affinity-propagation-de-Scikit-learn)</span></li>\n",
    "    \n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Lecture_du_dataset_via_Spark_et_conversion](#Lecture-du-dataset-via-Spark-et-conversion)</span></li>\n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Définition_des_préférences](#Définition-des-préférences)</span></li>\n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Définition_des_similarités](#Définition-des-similarités)</span></li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Actualisation_des_matrices_Availabilities_et_Responsabilities](#Actualisation-des-matrices-Availabilities-et-Responsabilities)</span></li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Test_sur_les_données_simulées](#Tests-sur-les-données-simulées)</span></li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Application_avec_les_Iris_de_Fisher](#Application-avec-les-Iris-de-Fisher)</span></li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Conclusions_et_critiques_du_travail_rendu](#Conclusions-et-critiques-du-travail-rendu)</span></li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Bibliographie](#Bibliographie)</span></li>\n",
    "\n",
    "\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "Commençons par importer les packages nécessaires au projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "import os\n",
    "chemin = '/Users/pierredesmet/Documents/Documents Word/Etudes/UTT/ENSAE/Semestre 1/Éléments logiciels pour le traitement des données massives'\n",
    "os.chdir(chemin)\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de l'_affinity propagation_ de Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous essayons dans un premier temps l'algorithme tel qu'il est implémenté dans Scikit-Learn (<a href = 'http://scikit-learn.org/stable/auto_examples/cluster/plot_affinity_propagation.html'>ici</a>), par curiosité.\n",
    "\n",
    "Nous générons pour cela un data set composé de 1000 individus décrits par 2 attributs. Ces données sont générées à partir de 3 centres, en dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Générons des données à partir de 3 centres initiaux\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=50, centers=centers, cluster_std=0.5,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10413749 -0.51168048]\n",
      " [ 1.76638961  1.73467938]\n",
      " [ 1.00525001 -0.10706475]\n",
      " [-1.33623022 -1.17977658]]\n",
      "[2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[:4])\n",
    "print(labels_true[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de ces données, nous pouvons lancer l'algorithme de Scikit-Learn, lequel propose effectivement **3 centres** pour segmenter les donneés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 3\n",
      "Homogeneity: 0.931\n"
     ]
    }
   ],
   "source": [
    "af = AffinityPropagation().fit(X) # @param : preference=-50\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "print('Estimated number of clusters: %d' % len(cluster_centers_indices))\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les centres retenus sont :\n",
      " [[ 1.06345605 -0.79900532]\n",
      " [-1.31716105 -1.18137058]\n",
      " [ 1.38051886  1.06083751]]\n"
     ]
    }
   ],
   "source": [
    "print('Les centres retenus sont :\\n',X[cluster_centers_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons que si l'on augmentait à 1000 le nombre d'individus générés, cet algorithme proposerait beaucoup plus de partitions (258)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture du dataset _via_ Spark et conversion\n",
    "Comme précédemment, nous allons générer un jeu de données avec un peu plus d'individus cette fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = [[4, 4], [-5, -5], [1, 1]]\n",
    "X, labels_true = make_blobs(n_samples=1500, centers=centers, cluster_std=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('Dataset.csv', index = False, header = False) # enregistrement des enregistrements X...\n",
    "data = sc.textFile('Dataset.csv').cache()# ...et lecture de ces derniers avec Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conversion en float des strings\n",
    "n_obs = data.count() \n",
    "n_cols = len(data.take(1)[0])\n",
    "data = data.map(lambda line : [float(line[i]) for i in range(n_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-4.143847389328352, -5.396057510282575],\n",
       " [1.4130628542155965, 0.9711217208106436],\n",
       " [-4.770207547582972, -4.85997106998116]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print des 3 premières observations\n",
    "data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque les données ne sont pas sur la même échelle, il vaut mieux les centrer et les réduire. Ici ce n'est pas nécessaire, mais faisons-le tout de même pour l'exemple.\n",
    "\n",
    "**Remarque** : nous aurions aussi pu utiliser la fonction `sklearn.preprocessing.scale` de Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# La transposée d'un RDD sert pour centrer-réduire\n",
    "def transpose_rdd(rdd):\n",
    "    return sc.parallelize(np.array(rdd.collect()).transpose())  \n",
    "\n",
    "def centre_reduit(rdd):\n",
    "    data_transposed = transpose_rdd(rdd)\n",
    "    data_processed_rdd = data_transposed.map(lambda record : (record-np.mean(record)) / np.std(record))\n",
    "    return transpose_rdd(data_processed_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.09866357, -1.43086088]),\n",
       " array([ 0.38183502,  0.25986154]),\n",
       " array([-1.26554143, -1.28851003])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On centre et on réduit toutes les données\n",
    "data = centre_reduit(data)\n",
    "data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des préférences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6711374680938509e-17, 3.6711374680938509e-17, 3.6711374680938509e-17]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cette fonction retourne un vecteur composé des moyennes (resp. médianes) de toutes les données\n",
    "def preference(rdd,fonction):\n",
    "    if fonction == 'moyenne':\n",
    "        vecteur = rdd.map(lambda feature : np.mean(feature))\n",
    "        return [vecteur.mean()]*rdd.count()\n",
    "    elif fonction == 'médiane':\n",
    "        median = np.median(pd.DataFrame(rdd.collect()))\n",
    "        return [median]*rdd.count()\n",
    "# test\n",
    "pref = preference(data,'moyenne')\n",
    "pref[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des similarités\n",
    "L'algorithme d'_affinity propagation_ utilise une matrice de similarité, dont les coefficients $c_{i,j}$ correspondent à la similarité (mesure euclidienne négative) entre une observation $x_i$ et une observation $x_j$.\n",
    "\n",
    "Pour calculer cette matrice, nous définirons plusieurs fonctions dont les dépendances fonctionnelles et les rôles sont précisés ci-dessous.\n",
    "<img src = 'http://img11.hostingpics.net/pics/942659Capturedcran20170119173305.png'/ width = 800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accès à des élements d'une RDD _via_ leur indice\n",
    "Par la suite, il sera pratique d'accéder aux éléments des _Resilient Distributed Dataset_ par leur indice. Créons la fonction permettant cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retourne la valeur associée à un indice\n",
    "def index_to_value(rdd,index):\n",
    "    keyval = rdd.zipWithIndex().map(lambda item : (item[1],item[0]))\n",
    "    return keyval.lookup(index-1)\n",
    "# test\n",
    "rdd_test = sc.parallelize(['5','6','7'])\n",
    "index_to_value(rdd_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance euclidienne négative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retourne la distance euclidienne négative entre deux vecteurs x1 et x2\n",
    "def similarity(x1,x2):\n",
    "    sim = np.linalg.norm(np.array(x1)-np.array(x2))\n",
    "    return(-sim*sim)\n",
    "# Test\n",
    "similarity([1,2,3],[3,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour des besoins futurs, on souhaite connaître \"la similarité d'une chaîne de caractère\", p. ex. \"12.34\". Celle-ci correspond à la distance euclidienne négative entre l'observation $x_{12}$ et l'observation $x_{34}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13186194667095397"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retourne_similarite(chaine):\n",
    "    ligne_num = int(chaine.split('.')[0])\n",
    "    colonne_num = int(chaine.split('.')[1])\n",
    "    return similarity(X[ligne_num-1], X[colonne_num-1]) # utilise un df pandas\n",
    "    #return similarity(index_to_value(data,ligne_num),index_to_value(data,colonne_num)) #utilise un rdd pyspark\n",
    "# Test\n",
    "retourne_similarite(\"12.34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice d'index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthodologie que nous adopterons est la suivante. Nous souhaitons définir une \"matrice d'index\" (à gauche), laquelle permettra de calculer de façon parallèle la matrice de similarité (à droite), ici dans le cas de $n$ = 300 individus.\n",
    "<img src = \"http://img11.hostingpics.net/pics/226582Capturedcran20170119171946.png\"/>\n",
    "\n",
    "**Remarque** : le coût algorithmique pour générer cette matrice est grand, $o(n^2)$. On le considèrera cependant comme tolérable, puisque qu'il n'est nécessaire de l'exécuter qu'une seule fois. En effet, une fois le fichier Excel créé, les exécutions ultérieures du programme n'ont plus qu'à importer le classeur. Si l'on dispose de ce classeur, il est donc possible de passer directement au bloc suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.05421900749207\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "#     Attention : portion de code chronophage       #\n",
    "#####################################################\n",
    "# Création d'une matrice d'index\n",
    "debut = t.time()\n",
    "mat = [[None]*data.count()]*data.count()\n",
    "#mat = pd.DataFrame(mat)\n",
    "for i in np.arange(0,data.count()):\n",
    "    for j in np.arange(0,data.count()):\n",
    "        mat[i][j] = str(i+1)+'.'+str(j+1)\n",
    "print(t.time()-debut)\n",
    "\n",
    "#Il peut être intéressant de sauvegarder cette matrice pour la charger plus rapidement par la suite.\n",
    "#pd.DataFrame(mat).to_csv(\"Matrice_index.csv\") TODO : decommenter cette ligne dangeureuse à la toute fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargeons la matrice d'index (déjà) créée dans un RDD \n",
    "#On ne conserve que le nombre de colonnes nécessaire :\n",
    "mat_rdd = sc.textFile(\"Matrice_index.csv\").map(lambda line: line.split(\";\")).map(lambda ligne : ligne[:n_obs])#.filter(lambda line: len(line)<=n_obs)\n",
    "\n",
    "# On ne conserve que le nombre de lignes nécessaire :\n",
    "mat_rdd = sc.parallelize(mat_rdd.take(n_obs)) # TODO : à optimiser, pas besoin de repasser par python normalement\n",
    "\n",
    "# Test\n",
    "mat_rdd.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice d'index est telle que l'élément en position (i,j) soit la chaîne de caractère \"i+1.j+1\" comme on le constate ci-dessous. Ceci est lié à l'indexation des RDD qui commence en 1, et non en 0 comme les DataFrames Pandas.\n",
    "\n",
    "**Remarque** : une autre façon de procéder est de créer la matrice d'index _via_ Excel, en copiant dans chaque cellule d'une plage `=CONCATENER(LIGNE();'.';COLONNE())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la matrice de similarité entre les observations\n",
    "Nous disposons à présent de toutes les fonctions nécessaires pour calculer la matrice des similarités. Dans un premier temps, on initialise cette matrice avec des valeurs nulles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.0', '-71.4202228157', '-0.679715719324']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_similarity_row(row):\n",
    "    modified_row = [0]*len(row)\n",
    "    for (i,item) in zip(range(0,len(row)),row):\n",
    "        modified_row[i] = str(retourne_similarite(item)) #if retourne_similarite(item)!=0 else str(pref[0])\n",
    "    return modified_row\n",
    "# test\n",
    "distances_row = fill_similarity_row(['1.1','1.2','1.3'])\n",
    "#distances_row = fill_similarity_row(mat_rdd.take(1))\n",
    "distances_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data.collect()) #Nécessaire car Spark ne peut travailler qu'avec un RDD à la fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusque là nous avons essentiellement défini les fontions utiles au programme. À présent, nous \"mappons\" la matrice d'index à l'aide de ces fonctions.\n",
    "De part la _lasy evaluation_, la portion de code suivante n'est exécutée que lorsque la fonction `collect()` est appelée, au bloc suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat_similarites = mat_rdd.map(lambda ligne : fill_similarity_row(ligne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution :26.98\n"
     ]
    }
   ],
   "source": [
    "import time as t\n",
    "debut = t.time()\n",
    "mat_similarites_df = pd.DataFrame(mat_similarites.collect())\n",
    "fin = t.time()\n",
    "print('Temps d\\'exécution :%.2f'%(fin-debut))\n",
    "#mat_similarites.saveAsTextFile('matrice_similarites.txt') # Does'nt work...?\n",
    "mat_similarites_df.to_csv(\"matrice_similarites.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque : ** vu que la matrice de similarité est symétrique, trouver un moyen de ne remplir que la moitié supérieure permettrait de diviser par 2 le temps de calcul. En python 'pur', cela pourrait se faire avec la fonction <a href = 'https://docs.scipy.org/doc/numpy/reference/generated/numpy.tril.html'> `np.tril()`</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualisation des matrices _Availabilities_ et _Responsabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = pd.read_csv(\"matrice_similarites.csv\", delimiter=\";\", index_col=False)\n",
    "S.drop(S.columns[[0]], axis=1, inplace=True) # suppression de la 1ère colonne \n",
    "S.to_csv('matrice_sim.csv', index = False, header = False)\n",
    "\n",
    "Srdd = sc.textFile(\"matrice_sim.csv\").cache()\n",
    "S    = S.as_matrix() # matrix version python\n",
    "rdd  = sc.parallelize(S) #version rdd à gérer plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def actualise_A_and_R(S,R,A,coefficient_lissage,suivi_iteration):\n",
    "    if (suivi_iteration):\n",
    "        print(\"Rancien\",\"\\n\",R)\n",
    "        print(\"S\",\"\\n\",S)\n",
    "        print(\"A actuel\",\"\\n\",A)\n",
    "    nbre_points = S.shape[0] # Nombre de points\n",
    "    \n",
    "    ###################################\n",
    "    ##  Calcul des responsabilities  ##\n",
    "    ###################################\n",
    "    \n",
    "    # On stocke la matrice de resultat intermédiaire dans la matrice resultat\n",
    "    resultat = np.zeros((nbre_points , nbre_points ))\n",
    "    indices_des_points=np.arange(nbre_points)\n",
    "    # On commence par ajouter la matrice A et la matrice S\n",
    "    np.add(A,S,resultat) \n",
    "    # On recupère les indices des valeurs maximales sur chaque colonne\n",
    "    I = np.argmax(resultat, axis=1) \n",
    "\n",
    "    # On recupère les valeurs maximales sur chaque colonne\n",
    "    Y = resultat[indices_des_points, I]   \n",
    "    resultat[indices_des_points, I] = -np.inf\n",
    "    Y2 = np.max(resultat, axis=1)\n",
    "\n",
    "    # On soustrait ces valeurs à la matrice de similarité\n",
    "    np.subtract(S, Y[:, None], resultat)\n",
    "\n",
    "    resultat[indices_des_points, I] = S[indices_des_points, I] - Y2\n",
    "\n",
    "    # Lissage de la matrice R\n",
    "    resultat=(1-coefficient_lissage)*resultat\n",
    "    R=coefficient_lissage*R + resultat\n",
    "    \n",
    "    if(suivi_iteration):\n",
    "        print(\"R actualisé\",\"\\n\",R)\n",
    "    \n",
    "    ###################################\n",
    "    ###   Calcul des availibities   ###\n",
    "    ###################################\n",
    "\n",
    "    np.maximum(R, 0, resultat) #On recupère le maximum de chaque ligne\n",
    "\n",
    "    resultat.flat[::nbre_points + 1] = R.flat[::nbre_points + 1]\n",
    "\n",
    "    resultat -= np.sum(resultat, axis=0)\n",
    "\n",
    "    self_availabilities = np.diag(resultat).copy()\n",
    "\n",
    "    resultat.clip(0, np.inf, resultat)\n",
    "\n",
    "    resultat.flat[::nbre_points + 1] = self_availabilities\n",
    "\n",
    "    # lissage de la matrice des availibilities\n",
    "    A=coefficient_lissage*A - (1-coefficient_lissage)*resultat\n",
    "    if(suivi_iteration):\n",
    "        print(\"A actualisé\",A)\n",
    "        \n",
    "    return(R,A) #on retourne les deux matrices actualisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_affinity_clustering(S, pref, coefficient_lissage, nb_iterations, suivi_iteration = False):\n",
    "    # On place la valeur de preference sur la diagonale de la matrice ( on prend le minimum par défaut)\n",
    "    nbre_points = S.shape[0] # Nombre de points\n",
    "    S.flat[::(nbre_points + 1)] = pref\n",
    "    \n",
    "    ### Initialisation des deux matrices Availabilities\n",
    "    A = np.zeros((nbre_points,nbre_points))\n",
    "    R = np.zeros((nbre_points,nbre_points))\n",
    "    iteration=1\n",
    "    while (iteration<=nb_iterations):\n",
    "        R,A=actualise_A_and_R(S=S,R=R,A=A,coefficient_lissage=0.5,suivi_iteration=suivi_iteration)\n",
    "        iteration=iteration+1\n",
    "        \n",
    "    # Affectation des clusters\n",
    "    E = R + A\n",
    "    is_cluster = np.where(np.diag(E)>0)[0] #is.cluster renvoie les indices des points representant chaque cluster\n",
    "    K = is_cluster.size # Nombre de clusters\n",
    "    # On renumérote les clusters de 0,1,2..\n",
    "    numeros_clusters = S[:,is_cluster].argmax(1) \n",
    "    numeros_clusters[is_cluster] = np.arange(K)\n",
    "    #On affecte chaque point à son cluster\n",
    "    cluster_affecte = is_cluster[numeros_clusters]\n",
    "   \n",
    "    # Affichage des résultats\n",
    "    print(\"Nombre_de_clusters trouvés:\",K)\n",
    "    print(\"\\t\")\n",
    "    clusters_tries = [(list(cluster_affecte).count(x),x) for x in is_cluster]\n",
    "    clusters_tries.sort(reverse=True)\n",
    "\n",
    "    for numero_cluster,(nb_membres, representant) in enumerate(clusters_tries) :\n",
    "        print ('Cluster n°%d  contenant %d points -->Représentant: point numéro %d'%(numero_cluster,nb_membres,representant))\n",
    "        idxs = filter(lambda x: x[1] == representant, zip(range(len(cluster_affecte)),cluster_affecte))\n",
    "        print (\"Membres:\",[x[0] for x in idxs])\n",
    "        print(\"\\t\")\n",
    "    return(R,A,K,is_cluster,cluster_affecte,numeros_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests sur les données simulées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre_de_clusters trouvés: 118\n",
      "\t\n",
      "Cluster n°0  contenant 5 points -->Représentant: point numéro 95\n",
      "Membres: [35, 95, 110, 127, 130]\n",
      "\t\n",
      "Cluster n°1  contenant 4 points -->Représentant: point numéro 126\n",
      "Membres: [74, 83, 126, 147]\n",
      "\t\n",
      "Cluster n°2  contenant 3 points -->Représentant: point numéro 141\n",
      "Membres: [13, 31, 141]\n",
      "\t\n",
      "Cluster n°3  contenant 3 points -->Représentant: point numéro 136\n",
      "Membres: [113, 136, 149]\n",
      "\t\n",
      "Cluster n°4  contenant 3 points -->Représentant: point numéro 132\n",
      "Membres: [12, 50, 132]\n",
      "\t\n",
      "Cluster n°5  contenant 3 points -->Représentant: point numéro 121\n",
      "Membres: [99, 121, 140]\n",
      "\t\n",
      "Cluster n°6  contenant 3 points -->Représentant: point numéro 96\n",
      "Membres: [67, 96, 111]\n",
      "\t\n",
      "Cluster n°7  contenant 3 points -->Représentant: point numéro 87\n",
      "Membres: [87, 90, 138]\n",
      "\t\n",
      "Cluster n°8  contenant 3 points -->Représentant: point numéro 68\n",
      "Membres: [68, 88, 146]\n",
      "\t\n",
      "Cluster n°9  contenant 3 points -->Représentant: point numéro 36\n",
      "Membres: [3, 36, 71]\n",
      "\t\n",
      "Cluster n°10  contenant 3 points -->Représentant: point numéro 28\n",
      "Membres: [28, 47, 53]\n",
      "\t\n",
      "Cluster n°11  contenant 3 points -->Représentant: point numéro 11\n",
      "Membres: [11, 75, 89]\n",
      "\t\n",
      "Cluster n°12  contenant 2 points -->Représentant: point numéro 131\n",
      "Membres: [79, 131]\n",
      "\t\n",
      "Cluster n°13  contenant 2 points -->Représentant: point numéro 115\n",
      "Membres: [101, 115]\n",
      "\t\n",
      "Cluster n°14  contenant 2 points -->Représentant: point numéro 102\n",
      "Membres: [102, 108]\n",
      "\t\n",
      "Cluster n°15  contenant 2 points -->Représentant: point numéro 41\n",
      "Membres: [41, 69]\n",
      "\t\n",
      "Cluster n°16  contenant 2 points -->Représentant: point numéro 2\n",
      "Membres: [2, 44]\n",
      "\t\n",
      "Cluster n°17  contenant 1 points -->Représentant: point numéro 148\n",
      "Membres: [148]\n",
      "\t\n",
      "Cluster n°18  contenant 1 points -->Représentant: point numéro 145\n",
      "Membres: [145]\n",
      "\t\n",
      "Cluster n°19  contenant 1 points -->Représentant: point numéro 144\n",
      "Membres: [144]\n",
      "\t\n",
      "Cluster n°20  contenant 1 points -->Représentant: point numéro 143\n",
      "Membres: [143]\n",
      "\t\n",
      "Cluster n°21  contenant 1 points -->Représentant: point numéro 142\n",
      "Membres: [142]\n",
      "\t\n",
      "Cluster n°22  contenant 1 points -->Représentant: point numéro 139\n",
      "Membres: [139]\n",
      "\t\n",
      "Cluster n°23  contenant 1 points -->Représentant: point numéro 137\n",
      "Membres: [137]\n",
      "\t\n",
      "Cluster n°24  contenant 1 points -->Représentant: point numéro 135\n",
      "Membres: [135]\n",
      "\t\n",
      "Cluster n°25  contenant 1 points -->Représentant: point numéro 134\n",
      "Membres: [134]\n",
      "\t\n",
      "Cluster n°26  contenant 1 points -->Représentant: point numéro 133\n",
      "Membres: [133]\n",
      "\t\n",
      "Cluster n°27  contenant 1 points -->Représentant: point numéro 129\n",
      "Membres: [129]\n",
      "\t\n",
      "Cluster n°28  contenant 1 points -->Représentant: point numéro 128\n",
      "Membres: [128]\n",
      "\t\n",
      "Cluster n°29  contenant 1 points -->Représentant: point numéro 125\n",
      "Membres: [125]\n",
      "\t\n",
      "Cluster n°30  contenant 1 points -->Représentant: point numéro 124\n",
      "Membres: [124]\n",
      "\t\n",
      "Cluster n°31  contenant 1 points -->Représentant: point numéro 123\n",
      "Membres: [123]\n",
      "\t\n",
      "Cluster n°32  contenant 1 points -->Représentant: point numéro 122\n",
      "Membres: [122]\n",
      "\t\n",
      "Cluster n°33  contenant 1 points -->Représentant: point numéro 120\n",
      "Membres: [120]\n",
      "\t\n",
      "Cluster n°34  contenant 1 points -->Représentant: point numéro 119\n",
      "Membres: [119]\n",
      "\t\n",
      "Cluster n°35  contenant 1 points -->Représentant: point numéro 118\n",
      "Membres: [118]\n",
      "\t\n",
      "Cluster n°36  contenant 1 points -->Représentant: point numéro 117\n",
      "Membres: [117]\n",
      "\t\n",
      "Cluster n°37  contenant 1 points -->Représentant: point numéro 116\n",
      "Membres: [116]\n",
      "\t\n",
      "Cluster n°38  contenant 1 points -->Représentant: point numéro 114\n",
      "Membres: [114]\n",
      "\t\n",
      "Cluster n°39  contenant 1 points -->Représentant: point numéro 112\n",
      "Membres: [112]\n",
      "\t\n",
      "Cluster n°40  contenant 1 points -->Représentant: point numéro 109\n",
      "Membres: [109]\n",
      "\t\n",
      "Cluster n°41  contenant 1 points -->Représentant: point numéro 107\n",
      "Membres: [107]\n",
      "\t\n",
      "Cluster n°42  contenant 1 points -->Représentant: point numéro 106\n",
      "Membres: [106]\n",
      "\t\n",
      "Cluster n°43  contenant 1 points -->Représentant: point numéro 105\n",
      "Membres: [105]\n",
      "\t\n",
      "Cluster n°44  contenant 1 points -->Représentant: point numéro 104\n",
      "Membres: [104]\n",
      "\t\n",
      "Cluster n°45  contenant 1 points -->Représentant: point numéro 103\n",
      "Membres: [103]\n",
      "\t\n",
      "Cluster n°46  contenant 1 points -->Représentant: point numéro 100\n",
      "Membres: [100]\n",
      "\t\n",
      "Cluster n°47  contenant 1 points -->Représentant: point numéro 98\n",
      "Membres: [98]\n",
      "\t\n",
      "Cluster n°48  contenant 1 points -->Représentant: point numéro 97\n",
      "Membres: [97]\n",
      "\t\n",
      "Cluster n°49  contenant 1 points -->Représentant: point numéro 94\n",
      "Membres: [94]\n",
      "\t\n",
      "Cluster n°50  contenant 1 points -->Représentant: point numéro 93\n",
      "Membres: [93]\n",
      "\t\n",
      "Cluster n°51  contenant 1 points -->Représentant: point numéro 92\n",
      "Membres: [92]\n",
      "\t\n",
      "Cluster n°52  contenant 1 points -->Représentant: point numéro 91\n",
      "Membres: [91]\n",
      "\t\n",
      "Cluster n°53  contenant 1 points -->Représentant: point numéro 86\n",
      "Membres: [86]\n",
      "\t\n",
      "Cluster n°54  contenant 1 points -->Représentant: point numéro 85\n",
      "Membres: [85]\n",
      "\t\n",
      "Cluster n°55  contenant 1 points -->Représentant: point numéro 84\n",
      "Membres: [84]\n",
      "\t\n",
      "Cluster n°56  contenant 1 points -->Représentant: point numéro 82\n",
      "Membres: [82]\n",
      "\t\n",
      "Cluster n°57  contenant 1 points -->Représentant: point numéro 81\n",
      "Membres: [81]\n",
      "\t\n",
      "Cluster n°58  contenant 1 points -->Représentant: point numéro 80\n",
      "Membres: [80]\n",
      "\t\n",
      "Cluster n°59  contenant 1 points -->Représentant: point numéro 78\n",
      "Membres: [78]\n",
      "\t\n",
      "Cluster n°60  contenant 1 points -->Représentant: point numéro 77\n",
      "Membres: [77]\n",
      "\t\n",
      "Cluster n°61  contenant 1 points -->Représentant: point numéro 76\n",
      "Membres: [76]\n",
      "\t\n",
      "Cluster n°62  contenant 1 points -->Représentant: point numéro 73\n",
      "Membres: [73]\n",
      "\t\n",
      "Cluster n°63  contenant 1 points -->Représentant: point numéro 72\n",
      "Membres: [72]\n",
      "\t\n",
      "Cluster n°64  contenant 1 points -->Représentant: point numéro 70\n",
      "Membres: [70]\n",
      "\t\n",
      "Cluster n°65  contenant 1 points -->Représentant: point numéro 66\n",
      "Membres: [66]\n",
      "\t\n",
      "Cluster n°66  contenant 1 points -->Représentant: point numéro 65\n",
      "Membres: [65]\n",
      "\t\n",
      "Cluster n°67  contenant 1 points -->Représentant: point numéro 64\n",
      "Membres: [64]\n",
      "\t\n",
      "Cluster n°68  contenant 1 points -->Représentant: point numéro 63\n",
      "Membres: [63]\n",
      "\t\n",
      "Cluster n°69  contenant 1 points -->Représentant: point numéro 62\n",
      "Membres: [62]\n",
      "\t\n",
      "Cluster n°70  contenant 1 points -->Représentant: point numéro 61\n",
      "Membres: [61]\n",
      "\t\n",
      "Cluster n°71  contenant 1 points -->Représentant: point numéro 60\n",
      "Membres: [60]\n",
      "\t\n",
      "Cluster n°72  contenant 1 points -->Représentant: point numéro 59\n",
      "Membres: [59]\n",
      "\t\n",
      "Cluster n°73  contenant 1 points -->Représentant: point numéro 58\n",
      "Membres: [58]\n",
      "\t\n",
      "Cluster n°74  contenant 1 points -->Représentant: point numéro 57\n",
      "Membres: [57]\n",
      "\t\n",
      "Cluster n°75  contenant 1 points -->Représentant: point numéro 56\n",
      "Membres: [56]\n",
      "\t\n",
      "Cluster n°76  contenant 1 points -->Représentant: point numéro 55\n",
      "Membres: [55]\n",
      "\t\n",
      "Cluster n°77  contenant 1 points -->Représentant: point numéro 54\n",
      "Membres: [54]\n",
      "\t\n",
      "Cluster n°78  contenant 1 points -->Représentant: point numéro 52\n",
      "Membres: [52]\n",
      "\t\n",
      "Cluster n°79  contenant 1 points -->Représentant: point numéro 51\n",
      "Membres: [51]\n",
      "\t\n",
      "Cluster n°80  contenant 1 points -->Représentant: point numéro 49\n",
      "Membres: [49]\n",
      "\t\n",
      "Cluster n°81  contenant 1 points -->Représentant: point numéro 48\n",
      "Membres: [48]\n",
      "\t\n",
      "Cluster n°82  contenant 1 points -->Représentant: point numéro 46\n",
      "Membres: [46]\n",
      "\t\n",
      "Cluster n°83  contenant 1 points -->Représentant: point numéro 45\n",
      "Membres: [45]\n",
      "\t\n",
      "Cluster n°84  contenant 1 points -->Représentant: point numéro 43\n",
      "Membres: [43]\n",
      "\t\n",
      "Cluster n°85  contenant 1 points -->Représentant: point numéro 42\n",
      "Membres: [42]\n",
      "\t\n",
      "Cluster n°86  contenant 1 points -->Représentant: point numéro 40\n",
      "Membres: [40]\n",
      "\t\n",
      "Cluster n°87  contenant 1 points -->Représentant: point numéro 39\n",
      "Membres: [39]\n",
      "\t\n",
      "Cluster n°88  contenant 1 points -->Représentant: point numéro 38\n",
      "Membres: [38]\n",
      "\t\n",
      "Cluster n°89  contenant 1 points -->Représentant: point numéro 37\n",
      "Membres: [37]\n",
      "\t\n",
      "Cluster n°90  contenant 1 points -->Représentant: point numéro 34\n",
      "Membres: [34]\n",
      "\t\n",
      "Cluster n°91  contenant 1 points -->Représentant: point numéro 33\n",
      "Membres: [33]\n",
      "\t\n",
      "Cluster n°92  contenant 1 points -->Représentant: point numéro 32\n",
      "Membres: [32]\n",
      "\t\n",
      "Cluster n°93  contenant 1 points -->Représentant: point numéro 30\n",
      "Membres: [30]\n",
      "\t\n",
      "Cluster n°94  contenant 1 points -->Représentant: point numéro 29\n",
      "Membres: [29]\n",
      "\t\n",
      "Cluster n°95  contenant 1 points -->Représentant: point numéro 27\n",
      "Membres: [27]\n",
      "\t\n",
      "Cluster n°96  contenant 1 points -->Représentant: point numéro 26\n",
      "Membres: [26]\n",
      "\t\n",
      "Cluster n°97  contenant 1 points -->Représentant: point numéro 25\n",
      "Membres: [25]\n",
      "\t\n",
      "Cluster n°98  contenant 1 points -->Représentant: point numéro 24\n",
      "Membres: [24]\n",
      "\t\n",
      "Cluster n°99  contenant 1 points -->Représentant: point numéro 23\n",
      "Membres: [23]\n",
      "\t\n",
      "Cluster n°100  contenant 1 points -->Représentant: point numéro 22\n",
      "Membres: [22]\n",
      "\t\n",
      "Cluster n°101  contenant 1 points -->Représentant: point numéro 21\n",
      "Membres: [21]\n",
      "\t\n",
      "Cluster n°102  contenant 1 points -->Représentant: point numéro 20\n",
      "Membres: [20]\n",
      "\t\n",
      "Cluster n°103  contenant 1 points -->Représentant: point numéro 19\n",
      "Membres: [19]\n",
      "\t\n",
      "Cluster n°104  contenant 1 points -->Représentant: point numéro 18\n",
      "Membres: [18]\n",
      "\t\n",
      "Cluster n°105  contenant 1 points -->Représentant: point numéro 17\n",
      "Membres: [17]\n",
      "\t\n",
      "Cluster n°106  contenant 1 points -->Représentant: point numéro 16\n",
      "Membres: [16]\n",
      "\t\n",
      "Cluster n°107  contenant 1 points -->Représentant: point numéro 15\n",
      "Membres: [15]\n",
      "\t\n",
      "Cluster n°108  contenant 1 points -->Représentant: point numéro 14\n",
      "Membres: [14]\n",
      "\t\n",
      "Cluster n°109  contenant 1 points -->Représentant: point numéro 10\n",
      "Membres: [10]\n",
      "\t\n",
      "Cluster n°110  contenant 1 points -->Représentant: point numéro 9\n",
      "Membres: [9]\n",
      "\t\n",
      "Cluster n°111  contenant 1 points -->Représentant: point numéro 8\n",
      "Membres: [8]\n",
      "\t\n",
      "Cluster n°112  contenant 1 points -->Représentant: point numéro 7\n",
      "Membres: [7]\n",
      "\t\n",
      "Cluster n°113  contenant 1 points -->Représentant: point numéro 6\n",
      "Membres: [6]\n",
      "\t\n",
      "Cluster n°114  contenant 1 points -->Représentant: point numéro 5\n",
      "Membres: [5]\n",
      "\t\n",
      "Cluster n°115  contenant 1 points -->Représentant: point numéro 4\n",
      "Membres: [4]\n",
      "\t\n",
      "Cluster n°116  contenant 1 points -->Représentant: point numéro 1\n",
      "Membres: [1]\n",
      "\t\n",
      "Cluster n°117  contenant 1 points -->Représentant: point numéro 0\n",
      "Membres: [0]\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "R,A,K,is_cluster,cluster_affecte,numero_clusters=run_affinity_clustering(S, pref = pref, coefficient_lissage=0.5,nb_iterations=500,suivi_iteration = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir implémenté l'affinity propagation sur des données simulées, essayons cet algorithme sur des données réelles : les Iris de Fisher.\n",
    "\n",
    "## Application avec les Iris de Fisher\n",
    "On ne présente plus le jeu de données _Iris_ (mais faisons-le quand même), largement utilisé en classification. \n",
    "\n",
    "150 fleurs décrites par 4 variables (la longueur et la largeur des sépales et pétales en cm) appartiennent à 3 espèces d'iris : setosa, virginica et versicolor. Le nombre \"logique\" de groupes que devrait trouver l'affinity propagation correspond donc au nombre d'espèces, 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = pd.DataFrame(datasets.load_iris().data)\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris.to_csv('iris.csv', index = False, header = False) # enregistrement des échantillons d'iris...\n",
    "data = sc.textFile('iris.csv').cache()# ...et lecture de ces derniers avec Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 3.5, 1.4, 0.2], [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = len(data.take(1)[0])\n",
    "n_obs  = data.count()\n",
    "# Conversion en float des strings\n",
    "data   = data.map(lambda line : [float(line[i]) for i in range(n_cols)])\n",
    "data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Récupération du nombre de colonnes et d'observations\n",
    "n_cols = len(data.take(1)[0])\n",
    "n_obs  = data.count()\n",
    "# Conversion en float des strings\n",
    "data   = data.map(lambda line : [float(line[i]) for i in range(n_cols)])\n",
    "# Centrage-réduction des données\n",
    "data = centre_reduit(data)\n",
    "# Création du vecteur de préférences\n",
    "pref = preference(data,'moyenne')\n",
    "# Chargement de la matrice d'index...\n",
    "mat_rdd = sc.textFile(\"Matrice_index.csv\").map(lambda line: line.split(\";\")).map(lambda ligne : ligne[:n_obs])\n",
    "# ...et rognage pour qu'elle soit aux dimensions d'Iris\n",
    "mat_rdd = sc.parallelize(mat_rdd.take(n_obs)) # TODO : à optimiser, pas besoin de repasser par python normalement\n",
    "# Collecte des données\n",
    "data = pd.DataFrame(data.collect())\n",
    "# Et c'est parti ! \n",
    "mat_similarites = mat_rdd.map(lambda ligne : fill_similarity_row(ligne))\n",
    "mat_similarites_df = pd.DataFrame(mat_similarites.collect())\n",
    "mat_similarites_df.to_csv(\"matrice_similarites_iris.csv\",sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = pd.read_csv(\"matrice_similarites_iris.csv\", delimiter=\";\", index_col=False)\n",
    "S.drop(S.columns[[0]], axis=1, inplace=True) # suppression de la 1ère colonne \n",
    "S.to_csv('matrice_sim.csv', index = False, header = False)\n",
    "\n",
    "Srdd = sc.textFile(\"matrice_sim.csv\").cache()\n",
    "S    = S.as_matrix() # matrix version python\n",
    "rdd  = sc.parallelize(S) #version rdd à gérer plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre_de_clusters trouvés: 3\n",
      "\t\n",
      "Cluster n°0  contenant 54 points -->Représentant: point numéro 54\n",
      "Membres: [0, 2, 10, 11, 14, 19, 33, 34, 37, 40, 43, 44, 45, 48, 54, 55, 56, 63, 66, 72, 73, 74, 75, 76, 78, 79, 83, 84, 87, 89, 90, 91, 94, 98, 102, 105, 107, 108, 113, 116, 117, 118, 122, 126, 131, 133, 134, 136, 137, 138, 143, 145, 147, 149]\n",
      "\t\n",
      "Cluster n°1  contenant 50 points -->Représentant: point numéro 49\n",
      "Membres: [3, 4, 5, 7, 8, 12, 15, 16, 20, 21, 22, 23, 24, 26, 30, 36, 39, 41, 42, 46, 49, 50, 51, 57, 59, 64, 67, 69, 71, 77, 85, 86, 96, 97, 99, 100, 101, 106, 109, 111, 115, 120, 121, 123, 124, 129, 132, 140, 142, 144]\n",
      "\t\n",
      "Cluster n°2  contenant 46 points -->Représentant: point numéro 128\n",
      "Membres: [1, 6, 9, 13, 17, 18, 25, 27, 28, 29, 31, 32, 35, 38, 47, 52, 53, 58, 60, 61, 62, 65, 68, 70, 80, 81, 82, 88, 92, 93, 95, 103, 104, 110, 112, 114, 119, 125, 127, 128, 130, 135, 139, 141, 146, 148]\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "R,A,K,is_cluster,cluster_affecte,numero_clusters=run_affinity_clustering(S, pref = -100, coefficient_lissage=0.5,nb_iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions et critiques du travail rendu\n",
    "\n",
    "- Tout n'est pas parallélisé\n",
    "- Comment jouer avec la préférence pour influencer le nombre de clusters ?\n",
    "\n",
    "- Ouverture : possibilité d'utiliser cet algo avant de faire tourner les k-means (gain de robustesse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie\n",
    "\n",
    "[1] W.C. Hung, C.Y. Chu and Y.L. Wu, \"Map Reduce Affinity Propagation Clustering Algorithm\", _International Journal of Electronics and Electrical Engineering, Vol. 3_, 4 August 2015.\n",
    "\n",
    "[2] B. J. Frey and D. Dueck, \"Clustering by passing Messages between Data Points\", _ScienceMag, Vol. 315_, 16 February 2007.\n",
    "\n",
    "[3] P. Redmond, J. A. Trono and D. Kronenberg, \"Affinity Propagation and other Data Clustering Techniques\", _SMC Clustering Paper Patrick Redmond_.\n",
    "\n",
    "[4] X. Dupré, \"Premiers pas avec Spark\", <a href = \"http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx2/notebooks/spark_first_steps.html\">\n",
    "*http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx2/notebooks/spark_first_steps.html*</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résolution distribuée d'un Sudoku \n",
    "Cette partie est un bonus, indépendant de l'algorithme présenté précédemment. L'objectif est de résoudre un sudoku de trois façons : en python, en programmation fonctionnelle, puis en utilisant une librairie _ad hoc_ de calcul parallèle. Nous comparerons alors les performances de ces 3 modes en termes de temps d'exécution.\n",
    "\n",
    "<ol> \n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Résolution_séquentielle_en_python](#Résolution-séquentielle-en-python)</span></li>\n",
    "    <ul>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Chargement_du_puzzle_a_résoudre_en_mémoire](#Chargement-du-puzzle-à-résoudre-en-mémoire)</span></li> \n",
    "        <li> <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Définition_des_fonctions_de_recherche](#Définition-des-fonctions-de-recherche)</span></li>\n",
    "        <li> <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Résolution](#Résolution)</span> </li>\n",
    "        </ul>\n",
    "<br/>\n",
    "    <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Version_parallélisée](#Version-parallélisée)</span></li>\n",
    "    <ul>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Programmation_fonctionnelle:_map()](#Programmation-fonctionnelle-:-map()</span> </li>\n",
    "        <li><span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Parallélisation_avec_Joblib](#Parallélisation-avec-Joblib)</span> </li>\n",
    "        </ul> \n",
    "</ol>\n",
    "\n",
    "**Remarque** : Le présent programme ne résout que des sudokus 'simples', i.e. pour lesquels il n'est pas nécessaire de faire d'hypothèse et dont la solution est unique. L'exécution globale du programme est rapide, ne pas hésiter à le rejouer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from functools import reduce\n",
    "import time as t\n",
    "os.chdir('/Users/pierredesmet/Documents/Documents Word/Etudes/UTT/ENSAE/Semestre 1/Éléments logiciels pour le traitement des données massives/Partie Sudoku')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution séquentielle en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons le sudoku suivant qui nous servira d'exemple de base. Il est tiré de la <a href = \"https://fr.wikipedia.org/wiki/Sudoku\"> page wikipédia </a>dédiée aux sudoku.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/ff/Sudoku-by-L2G-20050714.svg\" alt=\"sdk_wikipedia\" align = 'center' style=\"width:200px;height:200px;hspace=10\">\n",
    "\n",
    "Pour traduire cette image en données compréhensibles par une machine, nous renseignons manuellement les données dans un fichier Excel comme suit :\n",
    "<img src=\"http://img11.hostingpics.net/pics/501441Capturedcran20161227172935.png\" alt = \"sdk_csv\" style = \"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du puzzle à résoudre en mémoire\n",
    "Commençons par charger le sudoku à résoudre sous forme de Dataframe Pandas. Celui-ci est un fichier csv dont les cases non-résolues sont remplies avec des zéros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  0  0  7  0  0  0  0\n",
       "1  6  0  0  1  9  5  0  0  0\n",
       "2  0  9  8  0  0  0  0  6  0\n",
       "3  8  0  0  0  6  0  0  0  3\n",
       "4  4  0  0  8  0  3  0  0  1\n",
       "5  7  0  0  0  2  0  0  0  6\n",
       "6  0  6  0  0  0  0  2  8  0\n",
       "7  0  0  0  4  1  9  0  0  5\n",
       "8  0  0  0  0  8  0  0  7  9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sudoku1.csv', 'r', encoding='utf-8',newline = \"\") as f :\n",
    "    sdk = pd.read_csv(f, sep=';',\n",
    "    header=None,\n",
    "    index_col=False\n",
    "    )\n",
    "sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions de recherche\n",
    "Définissons tout d'abord 2 fonctions donnant les chiffres possibles pour une ligne unique (resp. une colonne unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 6, 8, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dispo_sur_ligne(ligne,sudoku):\n",
    "    posibilites = np.setdiff1d([1,2,3,4,5,6,7,8,9],sudoku.iloc[ligne],assume_unique = True)\n",
    "    return posibilites\n",
    "def dispo_sur_colonne(colonne,sudoku):\n",
    "    posibilites = np.setdiff1d([1,2,3,4,5,6,7,8,9],sudoku[colonne],assume_unique = True)\n",
    "    return posibilites\n",
    "# Test : quelles sont les possibilités sur la première ligne ?\n",
    "dispo_sur_ligne(0,sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les régions c'est un peu plus compliqué. Essayons déjà de connaître la région associée à une cellule donnée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Région de la cellule (2,7) : (0, 2)\n"
     ]
    }
   ],
   "source": [
    "def give_region(ligne,colonne):\n",
    "    idx_ligne,idx_colonne = (0,0)\n",
    "    if (ligne<=8) & (colonne <= 8):\n",
    "        idx_ligne = ligne//3\n",
    "        idx_colonne = colonne//3\n",
    "    return((idx_ligne,idx_colonne))\n",
    "# Test : quelle est la région de la cellule (2,7) ?\n",
    "print('Région de la cellule (2,7) :',give_region(2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Éléments de la région associée à la cellule (0,0) : [5, 3, 0, 6, 0, 0, 0, 9, 8]\n",
      "Nombres possibles dans cette région : [1 2 4 7]\n"
     ]
    }
   ],
   "source": [
    "# Recherche des éléments de la région associée à la cellule (i,j)\n",
    "def give_presents(i,j,sdk):\n",
    "    liste = []\n",
    "    liste.append(sdk.loc[i,j])\n",
    "    liste.append(sdk.loc[i,j+1])\n",
    "    liste.append(sdk.loc[i,j+2])\n",
    "    liste.append(sdk.loc[i+1,j])\n",
    "    liste.append(sdk.loc[i+1,j+1])\n",
    "    liste.append(sdk.loc[i+1,j+2])\n",
    "    liste.append(sdk.loc[i+2,j])\n",
    "    liste.append(sdk.loc[i+2,j+1])\n",
    "    liste.append(sdk.loc[i+2,j+2])\n",
    "    return liste\n",
    "# Test : quels sont les éléments de la région associée à la cellule (0,0) ?\n",
    "print('Éléments de la région associée à la cellule (0,0) :',give_presents(0,0,sdk))\n",
    "\n",
    "def dispo_sur_region(ligne,colonne,sudoku):\n",
    "    region = give_region(ligne,colonne)\n",
    "    if region == (0,0):\n",
    "        presents = give_presents(0,0,sdk)\n",
    "    elif region == (0,1):\n",
    "        presents = give_presents(0,3,sdk)\n",
    "    elif region == (0,2):\n",
    "        presents = give_presents(0,6,sdk)\n",
    "    elif region == (1,0):\n",
    "        presents = give_presents(3,0,sdk)\n",
    "    elif region == (1,1):\n",
    "        presents = give_presents(3,3,sdk)\n",
    "    elif region == (1,2):\n",
    "        presents = give_presents(3,6,sdk)\n",
    "    elif region == (2,0):\n",
    "        presents = give_presents(6,0,sdk)\n",
    "    elif region == (2,1):\n",
    "        presents = give_presents(6,3,sdk)\n",
    "    elif region == (2,2):\n",
    "        presents = give_presents(6,6,sdk)\n",
    "    possibilites = np.setdiff1d([1,2,3,4,5,6,7,8,9],presents,assume_unique = True)\n",
    "    return possibilites\n",
    "# Test : quels sont les possibilités pour la région associée à la cellule (0,0) ?\n",
    "print('Nombres possibles dans cette région :',dispo_sur_region(0,0,sdk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiffres possibles pour la cellule (1,1) : [2 4 7]\n"
     ]
    }
   ],
   "source": [
    "def possible(ligne,colonne,sudoku):\n",
    "    possibilites = reduce(np.intersect1d, (dispo_sur_ligne(ligne,sudoku),\n",
    "                                          dispo_sur_colonne(colonne,sudoku),\n",
    "                                          dispo_sur_region(ligne,colonne,sudoku)))\n",
    "    return possibilites\n",
    "# Test : quelles sont les valeurs possibles pour la cellule (2,4) ?\n",
    "print('Chiffres possibles pour la cellule (1,1) :', possible(1,1,sdk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résolution \n",
    "Place à la résolution ! Tant qu'il reste des zéros (i.e. des valeurs non trouvées), la recherche de solutions continue. S'il existe une unique solution, elle s'afiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 1.427 secondes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  4  6  7  8  9  1  2\n",
       "1  6  7  2  1  9  5  3  4  8\n",
       "2  1  9  8  3  4  2  5  6  7\n",
       "3  8  5  9  7  6  1  4  2  3\n",
       "4  4  2  6  8  5  3  7  9  1\n",
       "5  7  1  3  9  2  4  8  5  6\n",
       "6  9  6  1  5  3  7  2  8  4\n",
       "7  2  8  7  4  1  9  6  3  5\n",
       "8  3  4  5  2  8  6  1  7  9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debut = t.time()\n",
    "# Tant que toutes les cellules ne sont pas remplies...\n",
    "while np.count_nonzero(sdk)!= 81:\n",
    "    # Pour chaque cellule...\n",
    "    for i in np.arange(0,9):\n",
    "        for j in np.arange(0,9):\n",
    "            # Si une seule possibilité existe pour la cellule, y inscrire cette possibilité\n",
    "            if (len(possible(i,j,sdk)) == 1) & (sdk.loc[i,j] == 0): \n",
    "                sdk.loc[i,j] = possible(i,j,sdk)\n",
    "fin = t.time()\n",
    "print('Temps d\\'exécution : %.3f'%(fin-debut),'secondes.')\n",
    "sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version parallélisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmation fonctionnelle : map()\n",
    "On se propose de résoudre le même sudoku mais en programmation fonctionnelle. Rechargons-le dans un premier temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  0  0  7  0  0  0  0\n",
       "1  6  0  0  1  9  5  0  0  0\n",
       "2  0  9  8  0  0  0  0  6  0\n",
       "3  8  0  0  0  6  0  0  0  3\n",
       "4  4  0  0  8  0  3  0  0  1\n",
       "5  7  0  0  0  2  0  0  0  6\n",
       "6  0  6  0  0  0  0  2  8  0\n",
       "7  0  0  0  4  1  9  0  0  5\n",
       "8  0  0  0  0  8  0  0  7  9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relecture du Sudoku initial, non-résolu\n",
    "with open('sudoku1.csv', 'r', encoding='utf-8',newline = \"\") as f :\n",
    "    sdk = pd.read_csv(f, sep=';',\n",
    "    header=None,\n",
    "    index_col=False\n",
    "    )\n",
    "sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est d'arriver à une syntaxe de la forme **map(**`fonction`*, *`cases_à_résoudre`**)**, où `fonction` résout une unique case, et va être appliquée aux `cases_à_résoudre` en parallèle. \n",
    "\n",
    "Commençons par définir cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudoku avant...\n",
      "    0  1  2  3  4  5  6  7  8\n",
      "0  5  3  0  0  7  0  0  0  0\n",
      "1  6  0  0  1  9  5  0  0  0\n",
      "2  0  9  8  0  0  0  0  6  0\n",
      "3  8  0  0  0  6  0  0  0  3\n",
      "4  4  0  0  8  0  3  0  0  1\n",
      "5  7  0  0  0  2  0  0  0  6\n",
      "6  0  6  0  0  0  0  2  8  0\n",
      "7  0  0  0  4  1  9  0  0  5\n",
      "8  0  0  0  0  8  0  0  7  9\n",
      "\n",
      "...Sudoku après.\n",
      "    0  1  2  3  4  5  6  7  8\n",
      "0  5  3  0  0  7  0  0  0  0\n",
      "1  6  0  0  1  9  5  0  0  0\n",
      "2  0  9  8  0  0  0  0  6  0\n",
      "3  8  0  0  0  6  0  0  0  3\n",
      "4  4  0  0  8  5  3  0  0  1\n",
      "5  7  0  0  0  2  0  0  0  6\n",
      "6  0  6  0  0  0  0  2  8  0\n",
      "7  0  0  0  4  1  9  0  0  5\n",
      "8  0  0  0  0  8  0  0  7  9\n"
     ]
    }
   ],
   "source": [
    "# La fonction suivante résout une case individuelle (si c'est possible sans faire d'hypothèse)\n",
    "def resolution(case,sudoku):\n",
    "    possibilites = reduce(np.intersect1d, (dispo_sur_ligne(case[0],sudoku),\n",
    "                                          dispo_sur_colonne(case[1],sudoku),\n",
    "                                          dispo_sur_region(case[0],case[1],sudoku)))\n",
    "    if (len(possibilites) == 1): \n",
    "                sudoku.loc[case[0],case[1]] = possibilites\n",
    "# Test : résolvons la cellule centrale (4,4) :\n",
    "print('Sudoku avant...\\n',sdk)\n",
    "resolution([4,4],sdk)\n",
    "print('\\n...Sudoku après.\\n',sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous \"mappons\" chacune des cases non résolues avec la fonction de résolution individuelle. La <a href = 'https://docs.python.org/2/library/functions.html#map'> fonction map()</a> de python permet l'exécution parallélisée des calculs, comme en atteste la documentation :\n",
    "\n",
    "> Apply function to every item of iterable and return a list of the results. If additional iterable arguments are passed, function must take that many arguments and is applied to the items from all iterables in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 0.5514050 secondes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  4  6  7  8  9  1  2\n",
       "1  6  7  2  1  9  5  3  4  8\n",
       "2  1  9  8  3  4  2  5  6  7\n",
       "3  8  5  9  7  6  1  4  2  3\n",
       "4  4  2  6  8  5  3  7  9  1\n",
       "5  7  1  3  9  2  4  8  5  6\n",
       "6  9  6  1  5  3  7  2  8  4\n",
       "7  2  8  7  4  1  9  6  3  5\n",
       "8  3  4  5  2  8  6  1  7  9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tant que toutes les cellules ne sont pas remplies...\n",
    "debut = t.time()\n",
    "while np.count_nonzero(sdk)!= 81:\n",
    "    # Listons les indices des cases à résoudre\n",
    "    cases_à_remplir = []\n",
    "    for i in np.arange(0,9):\n",
    "            for j in np.arange(0,9):\n",
    "                if sdk.loc[i,j] == 0:\n",
    "                    cases_à_remplir.append([i,j])\n",
    "    list(map(lambda x : resolution(x,sdk),cases_à_remplir))\n",
    "fin = t.time()\n",
    "print('Temps d\\'exécution : %.7f'%(fin-debut),'secondes.')\n",
    "sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'exécution des calculs en parallèle nous fournit des résultats environ 2,5 fois plus rapidement qu'en python séquentiel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallélisation avec Joblib\n",
    "Testons à présent la librairie de calcul distribué Joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  0  0  7  0  0  0  0\n",
       "1  6  0  0  1  9  5  0  0  0\n",
       "2  0  9  8  0  0  0  0  6  0\n",
       "3  8  0  0  0  6  0  0  0  3\n",
       "4  4  0  0  8  0  3  0  0  1\n",
       "5  7  0  0  0  2  0  0  0  6\n",
       "6  0  6  0  0  0  0  2  8  0\n",
       "7  0  0  0  4  1  9  0  0  5\n",
       "8  0  0  0  0  8  0  0  7  9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relecture du Sudoku initial, non-résolu\n",
    "with open('sudoku1.csv', 'r', encoding='utf-8',newline = \"\") as f :\n",
    "    sdk = pd.read_csv(f, sep=';',\n",
    "    header=None,\n",
    "    index_col=False\n",
    "    )\n",
    "sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "#https://pythonhosted.org/joblib/parallel.html\n",
    "#http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/notebooks/td2a_cenonce_session_2D_parallelisation_local.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 0.9897740 secondes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  5  3  4  6  7  8  9  1  2\n",
       "1  6  7  2  1  9  5  3  4  8\n",
       "2  1  9  8  3  4  2  5  6  7\n",
       "3  8  5  9  7  6  1  4  2  3\n",
       "4  4  2  6  8  5  3  7  9  1\n",
       "5  7  1  3  9  2  4  8  5  6\n",
       "6  9  6  1  5  3  7  2  8  4\n",
       "7  2  8  7  4  1  9  6  3  5\n",
       "8  3  4  5  2  8  6  1  7  9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listons les indices des cases qu'il faut résoudre\n",
    "debut = t.time()\n",
    "while np.count_nonzero(sdk)!= 81:\n",
    "    cases_à_remplir = []\n",
    "    for i in np.arange(0,9):\n",
    "            for j in np.arange(0,9):\n",
    "                if sdk.loc[i,j] == 0:\n",
    "                    cases_à_remplir.append([i,j])\n",
    "    Parallel(n_jobs=2,backend = 'threading')(delayed(resolution) (x,sdk) for x in cases_à_remplir)\n",
    "fin = t.time()\n",
    "print('Temps d\\'exécution : %.7f'%(fin-debut),'secondes.')\n",
    "sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Pour un unique sudoku, les meilleurs résultats sont fournis par la programmation fonctionnelle (`map()`), puis par Joblib, et enfin en Python 'pur'. Attention cependant à ne pas tirer de conclusion rapide : sur de gros volumes de données, les performances pourraient bien être différentes.\n",
    "\n",
    "| **Méthode**           | Python \"pur\"    | Package Joblib | Programmation fonctionnelle |\n",
    "|-------------------|-----------------|----------------|-----------------------------|\n",
    "| **Temps d'exécution** | 1.1611 seconde | 1.1281 seconde        | 0.5435 seconde |"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
